{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   target      1600000 non-null  int64 \n",
      " 1   ids         1600000 non-null  int64 \n",
      " 2   date        1600000 non-null  object\n",
      " 3   flag        1600000 non-null  object\n",
      " 4   user        1600000 non-null  object\n",
      " 5   text        1600000 non-null  object\n",
      " 6   clean_text  1600000 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 85.4+ MB\n"
     ]
    }
   ],
   "source": [
    "%store -r data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000\n",
      "1600000\n"
     ]
    }
   ],
   "source": [
    "X = data['clean_text'].values\n",
    "y = data['target'].values\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1584000,) (1584000,) (16000,) (16000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=0)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_and_least_informative_features(vectorizer, clf, n=10):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    importances = list(clf.feature_importances_)\n",
    "    coefs_with_fns = sorted(zip(importances, feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[-n:])\n",
    "    print(\"Top \", n, \" most and least informative features\")\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, y_train, X_test, y_test, vectorizer, clf):\n",
    "    \n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    print(\"X_train_vec shape - \", X_train_vec.shape, \"\\n\")\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    print(\"X_test_vec shape - \", X_test_vec.shape, \"\\n\")\n",
    "    \n",
    "    y_pred = clf.fit(X_train_vec, y_train).predict(X_test_vec)\n",
    "    show_most_and_least_informative_features(vectorizer, clf, n=20)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0,4])\n",
    "    print()\n",
    "    print(\"Confusion matrix\\n\", cm, \"\\n\")\n",
    "\n",
    "    print(\"Classification report\\n\", classification_report(y_test, y_pred, target_names=['0','4']))\n",
    "    \n",
    "    return y_pred, vectorizer, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec shape -  (1584000, 243575) \n",
      "\n",
      "X_test_vec shape -  (16000, 243575) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  20  most and least informative features\n",
      "\t0.0000\taab            \t\t0.0079\tugh            \n",
      "\t0.0000\taabangan       \t\t0.0081\tawesome        \n",
      "\t0.0000\taabar          \t\t0.0084\thurts          \n",
      "\t0.0000\taabhar         \t\t0.0084\twish           \n",
      "\t0.0000\taabinker       \t\t0.0092\twhy            \n",
      "\t0.0000\taabot          \t\t0.0095\tsick           \n",
      "\t0.0000\taabout         \t\t0.0098\thate           \n",
      "\t0.0000\taabt           \t\t0.0101\tthank          \n",
      "\t0.0000\taacattyisamazing\t\t0.0106\tbut            \n",
      "\t0.0000\taaccee         \t\t0.0106\tsorry          \n",
      "\t0.0000\taacchhoo       \t\t0.0110\tlove           \n",
      "\t0.0000\taacck          \t\t0.0125\twork           \n",
      "\t0.0000\taacckk         \t\t0.0136\tthanks         \n",
      "\t0.0000\taacd           \t\t0.0154\tgood           \n",
      "\t0.0000\taach           \t\t0.0159\tmy             \n",
      "\t0.0000\taachar         \t\t0.0169\tno             \n",
      "\t0.0000\taache          \t\t0.0173\tmiss           \n",
      "\t0.0000\taachee         \t\t0.0182\tnot            \n",
      "\t0.0000\taachei         \t\t0.0245\tyou            \n",
      "\t0.0000\taachen         \t\t0.0268\tsad            \n",
      "\n",
      "Confusion matrix\n",
      " [[5857 2056]\n",
      " [1697 6390]] \n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      7913\n",
      "           4       0.76      0.79      0.77      8087\n",
      "\n",
      "    accuracy                           0.77     16000\n",
      "   macro avg       0.77      0.77      0.77     16000\n",
      "weighted avg       0.77      0.77      0.77     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest unigram baseline model\n",
    "y_pred_rf_1, vectorizer_rf_1, clf_rf_1 = model(X_train, y_train, X_test, y_test, CountVectorizer(encoding='latin-1'), RandomForestClassifier(max_depth=48, n_jobs=-1, random_state=0, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed: 252.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   50.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tf', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='latin-1',\n",
      "                input='content', lowercase=True, max_df=0.2, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
      "                stop_words=None, strip_accents=None,\n",
      "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None,\n",
      "                vocabulary=None)), ('rf', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=48, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=0, verbose=1,\n",
      "                       warm_start=False))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Random Forest unigram tf tuning\n",
    "pipeline = Pipeline([('tf', CountVectorizer(encoding='latin-1')),('rf', RandomForestClassifier(max_depth=48, n_jobs=-1, random_state=0, verbose=1))])\n",
    "parameters = {\n",
    "    'tf__max_df': (0.1, 0.2, 1.0),\n",
    "    'tf__min_df': (5, 10, 20, 1),\n",
    "    'rf__max_features': (\"auto\", 0.001, 0.005)\n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=3)\n",
    "grid_search_tune.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec shape -  (1584000, 243573) \n",
      "\n",
      "X_test_vec shape -  (16000, 243573) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 68.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed: 70.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 2426 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 2500 out of 2500 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  20  most and least informative features\n",
      "\t0.0000\taab            \t\t0.0085\tsucks          \n",
      "\t0.0000\taabangan       \t\t0.0086\tyour           \n",
      "\t0.0000\taabar          \t\t0.0094\tgreat          \n",
      "\t0.0000\taabhar         \t\t0.0097\tbad            \n",
      "\t0.0000\taabinker       \t\t0.0103\twork           \n",
      "\t0.0000\taabot          \t\t0.0105\tthank          \n",
      "\t0.0000\taabout         \t\t0.0107\tsorry          \n",
      "\t0.0000\taaccee         \t\t0.0112\thate           \n",
      "\t0.0000\taacck          \t\t0.0114\twish           \n",
      "\t0.0000\taach           \t\t0.0119\tsick           \n",
      "\t0.0000\taache          \t\t0.0120\tbut            \n",
      "\t0.0000\taachei         \t\t0.0135\tmy             \n",
      "\t0.0000\taachens        \t\t0.0137\tgood           \n",
      "\t0.0000\taadn           \t\t0.0143\tno             \n",
      "\t0.0000\taae            \t\t0.0160\tlove           \n",
      "\t0.0000\taaeeaa         \t\t0.0175\tmiss           \n",
      "\t0.0000\taaeew          \t\t0.0189\tnot            \n",
      "\t0.0000\taafech         \t\t0.0216\tthanks         \n",
      "\t0.0000\taafter         \t\t0.0241\tsad            \n",
      "\t0.0000\taafyh          \t\t0.0276\tyou            \n",
      "\n",
      "Confusion matrix\n",
      " [[5953 1960]\n",
      " [1698 6389]] \n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      7913\n",
      "           4       0.77      0.79      0.78      8087\n",
      "\n",
      "    accuracy                           0.77     16000\n",
      "   macro avg       0.77      0.77      0.77     16000\n",
      "weighted avg       0.77      0.77      0.77     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest unigram tf best model\n",
    "y_pred_rf_2, vectorizer_rf_2, clf_rf_2 = model(X_train, y_train, X_test, y_test, CountVectorizer(encoding='latin-1', min_df=1, max_df=0.2), RandomForestClassifier(n_estimators=1000, max_depth=48, n_jobs=-1, random_state=0, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed: 243.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   47.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='latin-1',\n",
      "                input='content', lowercase=True, max_df=0.2, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)), ('rf', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=48, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=0, verbose=1,\n",
      "                       warm_start=False))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Random Forest unigram tf-idf tuning\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(encoding='latin-1')),('rf', RandomForestClassifier(max_depth=48, n_jobs=-1, random_state=0, verbose=1))])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.1, 0.2, 1.0),\n",
    "    'tfidf__min_df': (5, 10, 20, 1),\n",
    "    'rf__max_features': (\"auto\", 0.001, 0.005)\n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=3)\n",
    "grid_search_tune.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec shape -  (1584000, 243573) \n",
      "\n",
      "X_test_vec shape -  (16000, 243573) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   57.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 31.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  20  most and least informative features\n",
      "\t0.0000\taab            \t\t0.0084\tsucks          \n",
      "\t0.0000\taabangan       \t\t0.0085\tyour           \n",
      "\t0.0000\taabar          \t\t0.0095\tthank          \n",
      "\t0.0000\taabhar         \t\t0.0099\twork           \n",
      "\t0.0000\taabinker       \t\t0.0100\tbad            \n",
      "\t0.0000\taabot          \t\t0.0105\tsorry          \n",
      "\t0.0000\taabout         \t\t0.0106\tgreat          \n",
      "\t0.0000\taacattyisamazing\t\t0.0108\twish           \n",
      "\t0.0000\taaccee         \t\t0.0112\tbut            \n",
      "\t0.0000\taacchhoo       \t\t0.0114\thate           \n",
      "\t0.0000\taacck          \t\t0.0127\tsick           \n",
      "\t0.0000\taach           \t\t0.0139\tmy             \n",
      "\t0.0000\taachar         \t\t0.0142\tno             \n",
      "\t0.0000\taache          \t\t0.0143\tgood           \n",
      "\t0.0000\taachee         \t\t0.0159\tmiss           \n",
      "\t0.0000\taachei         \t\t0.0165\tlove           \n",
      "\t0.0000\taachen         \t\t0.0201\tnot            \n",
      "\t0.0000\taachens        \t\t0.0216\tthanks         \n",
      "\t0.0000\taachhoo        \t\t0.0235\tsad            \n",
      "\t0.0000\taadha          \t\t0.0301\tyou            \n",
      "\n",
      "Confusion matrix\n",
      " [[5932 1981]\n",
      " [1708 6379]] \n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      7913\n",
      "           4       0.76      0.79      0.78      8087\n",
      "\n",
      "    accuracy                           0.77     16000\n",
      "   macro avg       0.77      0.77      0.77     16000\n",
      "weighted avg       0.77      0.77      0.77     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest unigram tf-idf best model\n",
    "y_pred_rf_3, vectorizer_rf_3, clf_rf_3 = model(X_train, y_train, X_test, y_test, CountVectorizer(encoding='latin-1', max_df=0.2, min_df=1), RandomForestClassifier(n_estimators=1000, max_depth=48, n_jobs=-1, random_state=0, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec shape -  (1584000, 3594521) \n",
      "\n",
      "X_test_vec shape -  (16000, 3594521) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  8.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  20  most and least informative features\n",
      "\t0.0000\taa aa          \t\t0.0041\tdidn           \n",
      "\t0.0000\taa after       \t\t0.0041\thurts          \n",
      "\t0.0000\taa against     \t\t0.0042\tugh            \n",
      "\t0.0000\taa alcohol     \t\t0.0044\twant to        \n",
      "\t0.0000\taa all         \t\t0.0045\thate           \n",
      "\t0.0000\taa allstars    \t\t0.0047\tdon            \n",
      "\t0.0000\taa already     \t\t0.0050\tno             \n",
      "\t0.0000\taa am          \t\t0.0051\tstill          \n",
      "\t0.0000\taa aml         \t\t0.0051\tthanks for     \n",
      "\t0.0000\taa and         \t\t0.0054\thappy          \n",
      "\t0.0000\taa angrezo     \t\t0.0055\twish           \n",
      "\t0.0000\taa another     \t\t0.0057\tsorry          \n",
      "\t0.0000\taa anyone      \t\t0.0058\tmiss           \n",
      "\t0.0000\taa apr         \t\t0.0060\tgreat          \n",
      "\t0.0000\taa are         \t\t0.0065\tyour           \n",
      "\t0.0000\taa artifact    \t\t0.0084\tnot            \n",
      "\t0.0000\taa as          \t\t0.0085\tyou            \n",
      "\t0.0000\taa asyik       \t\t0.0117\twant           \n",
      "\t0.0000\taa at          \t\t0.0185\tsad            \n",
      "\t0.0000\taa baas        \t\t0.0185\tthanks         \n",
      "\n",
      "Confusion matrix\n",
      " [[5704 2209]\n",
      " [1671 6416]] \n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75      7913\n",
      "           4       0.74      0.79      0.77      8087\n",
      "\n",
      "    accuracy                           0.76     16000\n",
      "   macro avg       0.76      0.76      0.76     16000\n",
      "weighted avg       0.76      0.76      0.76     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest bigram baseline model\n",
    "y_pred_rf_4, vectorizer_rf_4, clf_rf_4 = model(X_train, y_train, X_test, y_test, CountVectorizer(encoding='latin-1', ngram_range=(1,2)), RandomForestClassifier(n_estimators=100, max_depth=64, n_jobs=-1, random_state=0, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed: 266.0min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tf', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='latin-1',\n",
      "                input='content', lowercase=True, max_df=0.2, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
      "                stop_words=None, strip_accents=None,\n",
      "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None,\n",
      "                vocabulary=None)), ('rf', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=64, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=0, verbose=1,\n",
      "                       warm_start=False))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  5.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Random Forest bigram tf tuning\n",
    "pipeline = Pipeline([('tf', CountVectorizer(encoding='latin-1')),('rf', RandomForestClassifier(max_depth=64, n_jobs=-1, random_state=0, verbose=1))])\n",
    "parameters = {\n",
    "    'tf__max_df': (0.1, 0.2, 1.0),\n",
    "    'tf__min_df': (5, 10, 20, 1),\n",
    "    'rf__max_features': (\"auto\", 0.0001, 0.0005)\n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=3)\n",
    "grid_search_tune.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec shape -  (1584000, 243573) \n",
      "\n",
      "X_test_vec shape -  (16000, 243573) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 52.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  20  most and least informative features\n",
      "\t0.0000\taabangan       \t\t0.0074\tyour           \n",
      "\t0.0000\taabar          \t\t0.0075\tsucks          \n",
      "\t0.0000\taabhar         \t\t0.0084\tthank          \n",
      "\t0.0000\taabinker       \t\t0.0090\tbad            \n",
      "\t0.0000\taabout         \t\t0.0090\twork           \n",
      "\t0.0000\taaccee         \t\t0.0095\tgreat          \n",
      "\t0.0000\taacd           \t\t0.0096\tsorry          \n",
      "\t0.0000\taach           \t\t0.0100\twish           \n",
      "\t0.0000\taache          \t\t0.0102\thate           \n",
      "\t0.0000\taachei         \t\t0.0108\tbut            \n",
      "\t0.0000\taachen         \t\t0.0114\tsick           \n",
      "\t0.0000\taadam          \t\t0.0131\tmy             \n",
      "\t0.0000\taadha          \t\t0.0133\tgood           \n",
      "\t0.0000\taadn           \t\t0.0140\tno             \n",
      "\t0.0000\taae            \t\t0.0155\tlove           \n",
      "\t0.0000\taaeeaa         \t\t0.0167\tmiss           \n",
      "\t0.0000\taafech         \t\t0.0178\tnot            \n",
      "\t0.0000\taaffrriiccaa   \t\t0.0198\tthanks         \n",
      "\t0.0000\taafter         \t\t0.0221\tsad            \n",
      "\t0.0000\taafyh          \t\t0.0288\tyou            \n",
      "\n",
      "Confusion matrix\n",
      " [[6009 1904]\n",
      " [1714 6373]] \n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      7913\n",
      "           4       0.77      0.79      0.78      8087\n",
      "\n",
      "    accuracy                           0.77     16000\n",
      "   macro avg       0.77      0.77      0.77     16000\n",
      "weighted avg       0.77      0.77      0.77     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest bigram tf best model\n",
    "y_pred_rf_5, vectorizer_rf_5, clf_rf_5 = model(X_train, y_train, X_test, y_test, CountVectorizer(encoding='latin-1', max_df=0.2, min_df=1), RandomForestClassifier(n_estimators=1000, max_depth=64, n_jobs=-1, random_state=0, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 63.8min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed: 249.1min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='latin-1',\n",
      "                input='content', lowercase=True, max_df=0.2, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)), ('rf', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=64, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=0, verbose=1,\n",
      "                       warm_start=False))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  4.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Random Forest bigram tf-idf tuning\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(encoding='latin-1')),('rf', RandomForestClassifier(max_depth=64, n_jobs=-1, random_state=0, verbose=1))])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.1, 0.2, 1.0),\n",
    "    'tfidf__min_df': (5, 10, 20, 1),\n",
    "    'rf__max_features': (\"auto\", 0.0001, 0.0005)\n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, verbose=3)\n",
    "grid_search_tune.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec shape -  (1584000, 243573) \n",
      "\n",
      "X_test_vec shape -  (16000, 243573) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 55.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  20  most and least informative features\n",
      "\t0.0000\taab            \t\t0.0075\tsucks          \n",
      "\t0.0000\taabangan       \t\t0.0084\tyour           \n",
      "\t0.0000\taabar          \t\t0.0087\tgreat          \n",
      "\t0.0000\taabhar         \t\t0.0092\tbad            \n",
      "\t0.0000\taabinker       \t\t0.0092\twish           \n",
      "\t0.0000\taabot          \t\t0.0098\tthank          \n",
      "\t0.0000\taabout         \t\t0.0103\tsick           \n",
      "\t0.0000\taabt           \t\t0.0105\tbut            \n",
      "\t0.0000\taacattyisamazing\t\t0.0108\twork           \n",
      "\t0.0000\taaccee         \t\t0.0110\thate           \n",
      "\t0.0000\taacchhoo       \t\t0.0117\tsorry          \n",
      "\t0.0000\taacck          \t\t0.0130\tmy             \n",
      "\t0.0000\taacckk         \t\t0.0132\tgood           \n",
      "\t0.0000\taach           \t\t0.0135\tno             \n",
      "\t0.0000\taachar         \t\t0.0142\tlove           \n",
      "\t0.0000\taache          \t\t0.0160\tmiss           \n",
      "\t0.0000\taachee         \t\t0.0181\tnot            \n",
      "\t0.0000\taachei         \t\t0.0211\tthanks         \n",
      "\t0.0000\taachen         \t\t0.0225\tsad            \n",
      "\t0.0000\taachhoo        \t\t0.0272\tyou            \n",
      "\n",
      "Confusion matrix\n",
      " [[6031 1882]\n",
      " [1731 6356]] \n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      7913\n",
      "           4       0.77      0.79      0.78      8087\n",
      "\n",
      "    accuracy                           0.77     16000\n",
      "   macro avg       0.77      0.77      0.77     16000\n",
      "weighted avg       0.77      0.77      0.77     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest bigram tf-idf best model\n",
    "y_pred_rf_6, vectorizer_rf_6, clf_rf_6 = model(X_train, y_train, X_test, y_test, TfidfVectorizer(encoding='latin-1', max_df=0.2, min_df=1), RandomForestClassifier(n_estimators=1000, max_depth=64, n_jobs=-1, random_state=0, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
