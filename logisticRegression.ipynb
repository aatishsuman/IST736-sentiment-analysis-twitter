{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   target      1600000 non-null  int64 \n",
      " 1   ids         1600000 non-null  int64 \n",
      " 2   date        1600000 non-null  object\n",
      " 3   flag        1600000 non-null  object\n",
      " 4   user        1600000 non-null  object\n",
      " 5   text        1600000 non-null  object\n",
      " 6   clean_text  1600000 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 85.4+ MB\n"
     ]
    }
   ],
   "source": [
    "%store -r data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000\n",
      "1600000\n"
     ]
    }
   ],
   "source": [
    "X = data['clean_text'].values\n",
    "y = data['target'].values\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1584000,) (1584000,) (16000,) (16000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=0)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, y_train, X_test, y_test, vectorizer, clf):\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    print(\"X_train_vec shape - \", X_train_vec.shape, \"\\n\")\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    print(\"X_test_vec shape - \", X_test_vec.shape, \"\\n\")\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    print(\"Accuracy - \", clf.score(X_test_vec, y_test))\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    return vectorizer, clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec shape -  (1584000, 243575) \n",
      "\n",
      "X_test_vec shape -  (16000, 243575) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  0.801125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.9min finished\n"
     ]
    }
   ],
   "source": [
    "# tf unigram\n",
    "vectorizer1, clf1, y_pred1 = model(X_train, y_train, X_test, y_test, CountVectorizer(encoding='latin-1'), LogisticRegression(max_iter=1000, n_jobs=-1, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec shape -  (1584000, 243575) \n",
      "\n",
      "X_test_vec shape -  (16000, 243575) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  0.8031875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "# tf-idf unigram\n",
    "vectorizer2, clf2, y_pred2 = model(X_train, y_train, X_test, y_test, TfidfVectorizer(encoding='latin-1'), LogisticRegression(max_iter=1000, n_jobs=-1, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec shape -  (1584000, 3594521) \n",
      "\n",
      "X_test_vec shape -  (16000, 3594521) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  0.8219375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 16.5min finished\n"
     ]
    }
   ],
   "source": [
    "# tf bigram\n",
    "vectorizer3, clf3, y_pred3 = model(X_train, y_train, X_test, y_test, CountVectorizer(encoding='latin-1', ngram_range=(1,2)), LogisticRegression(max_iter=1000, n_jobs=-1, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vec shape -  (1584000, 3594521) \n",
      "\n",
      "X_test_vec shape -  (16000, 3594521) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  0.824125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  7.2min finished\n"
     ]
    }
   ],
   "source": [
    "# tf-idf bigram\n",
    "vectorizer4, clf4, y_pred4 = model(X_train, y_train, X_test, y_test, TfidfVectorizer(encoding='latin-1', ngram_range=(1,2)), LogisticRegression(max_iter=1000, n_jobs=-1, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printErrors(y_pred, top=10):\n",
    "    print(*([(X_test[i], y_test[i], y_pred[i]) for i in range(len(y_test)) if y_pred[i] != y_test[i]][:top]), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram tf model\n",
      "('where the are my pinking shears rarararrarararr babyproofing while cutting stuff makes me stick shears random places forget them', 0, 4)\n",
      "('reply me pls', 4, 0)\n",
      "('morning twitter world gonna start my day with the coldest lucozade can find', 4, 0)\n",
      "('song of my life now your love is lie simple plan beautifulylost', 0, 4)\n",
      "('watching the last leno so glad got to go once', 0, 4)\n",
      "('dropped your books off in the library', 4, 0)\n",
      "('sun burns are noo fun bored sittin at home watching bride wars with my sister have good weekend everyone', 0, 4)\n",
      "('do more that anything', 0, 4)\n",
      "('ok was confused for moment have to agree that ur dad sure could ve timed the announcement diff time though', 0, 4)\n",
      "('my daddy lives in manchester love it there hull bitch have mate there and wanna go', 0, 4)\n",
      "('oh my jeebus slept all day how wonderful think hungry', 4, 0)\n",
      "('umm its getting betterr than before but its still pretty bad lol', 4, 0)\n",
      "('huh turns out like marmite when did stop being loved by all', 0, 4)\n",
      "('thanks really appreciate that my skin is acting up', 0, 4)\n",
      "('can feel my bottom and is now going to bed', 4, 0)\n",
      "('off to get ready for school now', 4, 0)\n",
      "('still trying to upload pics of my new hair gave myself first aide cut my hand with knife chopping onions ugh', 4, 0)\n",
      "('you re absolutely right was thinking today was the th oh well next year you must tell me all about it next week at', 0, 4)\n",
      "('wish was too', 4, 0)\n",
      "('konstantino firefox crash last months both in mac and pc and is very sloow', 4, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Bigram tf model\")\n",
    "printErrors(y_pred4, top=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
